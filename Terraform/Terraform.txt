Certification Question: 
-> https://github.com/devenes/HashiCorp-Certified-Terraform-Associate?tab=readme-ov-file
1) it is cloud agonistic (it can work with multy cloud): TRUE
2) Terraform can manage cross-clod dependencies: TRUE
3) It can manage things from on-Prem as well. TRUE
4) terraform will be install in Window, Linux, ios, FreeBSD, open BSD, salaries only.
5) plugin information stored in .terraform folder.
6) each provider have it's own plugins.
7) If terraform create any resources then it come or store in to state file.
8) drift -> changes between current state and desired state use terraform plan command to check this.






======================================22-09-2025==== Session 23=================================================
TERRAFORM - DAY 1: 22-09-2025
=============================

IAC: INFRASTRUCTURE AS CODE
---------------------------
→ Infrastructure refers to resources used to run applications on the cloud.
   Examples: EC2, S3, ELB, VPC, ASG, etc.

→ Traditional Deployment (Manual):
   1. Time-consuming
   2. Involves manual work
   3. High chance of human error

→ Solution: Automation using Terraform
   → Code-based infrastructure
   → Language: HCL (HashiCorp Configuration Language)

------------------------------------------------------------
WHAT IS TERRAFORM?
-------------------
→ A tool used to automate infrastructure deployment.
→ Free to use (not open source).
→ Platform independent.
→ Released in 2014.
→ Created by: Mitchell Hashimoto.
→ Owned by: HashiCorp (now maintained by IBM).
→ Written in: Go language.
→ Cloud Agnostic: Works with any cloud (AWS, Azure, GCP, etc.)
→ Can manage on-prem resources too.
→ Called an "IAC Tool".

------------------------------------------------------------
TERRAFORM WORKFLOW (IPAD):
---------------------------
I   : init
P  : plan
A  : apply
D : destroy

1) terraform init
   → Initializes the working environment.
   → Downloads required provider plugins (e.g., AWS, Azure).
   → Creates `.terraform` folder to store plugins.

2) terraform plan
   → Previews the changes that Terraform will make.
   → Compares current state with configuration.
   → Shows what will be created, updated, or deleted.

3) terraform apply
   → Applies the planned changes to the real infrastructure.
   → Actually creates, updates, or deletes resources.

4) terraform destroy
   → Deletes all resources managed by Terraform.
   → Used for teardown or cleanup.

------------------------------------------------------------
HOW TERRAFORM WORKS:
---------------------
→ Terraform uses code to automate infrastructure provisioning.
→ We write code in HCL (.tf files).
→ Based on inputs, Terraform creates real-world resources.

------------------------------------------------------------
ADVANTAGES OF TERRAFORM:
-------------------------
1. Reusable
2. Time-saving
3. Automation
4. Avoids manual errors
5. DRY Principle (Don’t Repeat Yourself)

------------------------------------------------------------
CLOUD-SPECIFIC ALTERNATIVES:
-----------------------------
→ AWS:    CFT (CloudFormation Template)
→ Azure:  ARM (Azure Resource Manager)
→ GCP:    GDE (Google Deployment Engine)

→ Terraform = Works across all clouds

------------------------------------------------------------
OTHER IAC TOOLS:
-----------------
→ Pulumi
→ OpenTofu
→ Ansible
→ Chef
→ Puppet

------------------------------------------------------------
TERRAFORM VS ANSIBLE:
----------------------
→ Terraform creates servers/infrastructure.
→ Ansible configures those servers (install software, set up apps, etc.).

------------------------------------------------------------
INSTALLING TERRAFORM (UBUNTU):
-------------------------------
Step 1: Install Terraform
wget -O - https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(grep -oP '(?<=UBUNTU_CODENAME=).*' /etc/os-release || lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
sudo apt update && sudo apt install terraform

Note:
→ Terraform is a 3rd-party tool.
→ Needs permissions to access AWS.
→ Use IAM Role or `aws configure`.

Step 2: AWS IAM Role

→ Use `aws configure` OR
→ Attach an IAM Role to the EC2 instance.
→ Check config: `ll ~/.aws/`

------------------------------------------------------------
TERRAFORM FILE STRUCTURE:
--------------------------
→ Configuration files end with `.tf`
→ Files contain:
   - Blocks
   - Labels (name, type)
   - Arguments (resource inputs)

Example:
--------

mkdir terraform
cd terraform
vim main.tf

# Sample Terraform Code

provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "one" {
  count         = 5
  ami           = "ami-03eb6185d756497f8"
  instance_type = "t2.micro"
 tags = {
    Name = "dev-server"
  }

}

Commands:
terraform init
terraform plan
terraform apply --auto-approve
terraform destroy --auto-approve

------------------------------------------------------------
STATE FILE:
-----------
→ Terraform uses a "state file" to track resources.
→ Filename: terraform.tfstate
→ Keeps infrastructure data.
→ Important: Must be kept safe and secure.
→ Losing it = loss of infrastructure tracking.

Commands:
terraform state list

------------------------------------------------------------
DESTROYING SPECIFIC RESOURCES:
-------------------------------
→ You can target specific resources to destroy.

List resources:
terraform state list

Single resource:
terraform destroy --auto-approve -target="aws_instance.one[3]"

Multiple resources:
terraform destroy --auto-approve -target="aws_instance.one[1]" -target="aws_instance.one[2]"

------------------------------------------------------------
FORMATTING TERRAFORM FILES:
----------------------------
Command:
terraform fmt

→ Automatically formats `.tf` files for readability.
→ Aligns and indents code properly.

------------------------------------------------------------
PLUGIN:
--------
→ Plugins are responsible for communicating with cloud providers.
→ Terraform downloads them during `init`.
→ Without plugins, resources cannot be created.


======================================23-09-2025==== Session 24========================================================
1) count
2) for_each
3) PARALLELISM
4) DEPENDS_ON
5) LIFECYCLE
	-> PREVENT DESTROY
	-> CREATE BEFORE DESTROY:
	-> IGNORE CHANGES


====================
META ARGUMENTS
====================

1. PARALLELISM:
--------------------
- By default, Terraform follows parallelism.
- It executes multiple resources at the same time.
- Default parallelism limit is 10.
- Terraform can create up to 10 resources at once.

Command:
terraform apply -auto-approve -parallelism=1

NOTE: This applies to both 'apply' and 'destroy' operations.

--------------------
2. DEPENDS_ON:
--------------------
- One resource's creation depends on another.
- This is called explicit dependency.

Example:
--------------------
provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "one" {
  ami           = "ami-046d18c147c36bef1"
  instance_type = "t2.micro"
  tags = {
    Name = "raham-server"
  }
}

resource "aws_s3_bucket" "two" {
  bucket     = "terraformbucketabcd123"
  depends_on = [aws_instance.one]
}

====================
COUNT
====================
- Used to create multiple similar resources.
- Can't be used for different configurations.

Example:
--------------------
provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "one" {
  count         = 3
  ami           = "ami-046d18c147c36bef1"
  instance_type = "t2.micro"
  tags = {
    Name = "dev-server-${count.index + 1}"
  }
}

NOTE: Cannot create resources with different configs.

====================
FOR_EACH
====================
- Used to loop through a set of values.
- Allows different configurations with less code.

Example:
--------------------
provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "one" {
  for_each      = toset(["dev-server", "test-server", "prod-server"])
  ami           = "ami-046d18c147c36bef1"
  instance_type = "t2.micro"
  tags = {
    Name = "${each.key}"
  }
}

====================
LIFECYCLE
====================

1. PREVENT DESTROY:
--------------------
- Prevents the resource from being destroyed.

Example:
--------------------
provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "one" {
  ami           = "ami-046d18c147c36bef1"
  instance_type = "t2.micro"
  tags = {
    Name = "raham-server"
  }
  
}

NOTE: Test with `terraform apply`

2. IGNORE CHANGES:
--------------------
- Ignores manual changes in current state during apply.

Example:
--------------------
provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "one" {
  ami           = "ami-046d18c147c36bef1"
  instance_type = "t2.micro"
  tags = {
    Name = "raham-server"
  }
  lifecycle {
    ignore_changes = all
  }
}

NOTE: Modify name manually in AWS console and test with `terraform apply`

3. CREATE BEFORE DESTROY:
--------------------
- Default behavior is destroy first, then create.
- This option changes it to create new first, then destroy old.

Example:
--------------------
provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "one" {
  ami           = "ami-0208b77a23d891325"
  instance_type = "t2.micro"
  tags = {
    Name = "raham-server"
  }
  lifecycle {
    create_before_destroy = true
  }
}

NOTE: Change AMI ID and apply.
======================================24-09-2025==== Session 25========================================================


TERRAFORM IMPORT
-------------------------
- When we create a resource manually, Terraform does not track it.
- The 'import' command is used to import that manually created resource into Terraform.
- Only one resource can be imported at a time (from CLI).
- Import can update both:
    1. State file only (NOT preferable)
    2. State file + Configuration file (PREFERRED)

1. FOR STATE FILE ONLY:
Command:
terraform import aws_instance.one i-0c23bdc1b7b73d61c

NOTE: This only updates the state file. No code is generated.

2. FOR STATE FILE + CONFIG FILE:
Steps:
- First create a manual EC2 instance via AWS Console.

Sample main.tf:

provider "aws" {
  region = "us-east-1"
}

import {
  to = aws_instance.one
  id = "i-0c23bdc1b7b73d61c"
}

Commands:
terraform plan -generate-config-out=ec2.tf
(Note: DELETE lines 21, 22, 68, 69, 70 from ec2.tf manually)

terraform apply -auto-approve
terraform state list
terraform destroy -auto-approve


TERRAFORM TAINT
-------------------------
- TAINT means recreating server.
- Manually marks a resource for recreation.
- Used when a resource fails to create properly.
- In newer Terraform versions, use `-replace` instead.

Command to taint:
terraform taint aws_instance.one[0]

To untaint:
terraform untaint aws_instance.one[0]

Check state:
terraform state list

Apply changes:
terraform apply --auto-approve


TERRAFORM REPLACE
-------------------------
- Preferred method in latest Terraform versions.

Command:
terraform apply --auto-approve -replace="aws_instance.one[0]"


CODE EXAMPLE (FOR TAINT/REPLACE):
-------------------------------------
provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "one" {
  count         = 2
  ami           = "ami-0866a3c8686eaeeba"
  instance_type = "t2.micro"
  tags = {
    Name = "pravesh"
  }
}


TERRAFORM VALIDATE
-------------------------
- Validates your Terraform `.tf` files.
- Will show errors if syntax is incorrect or variables are missing.

Command:
terraform validate


TERRAFORM PLAN
-------------------------
- Shows what changes will be made without applying them.
- Can save the plan for future use.

Commands:
terraform plan -out=myplan
terraform apply myplan
terraform plan -destroy


TERRAFORM REFRESH
-------------------------
- Refreshes the state file by comparing with actual infrastructure.
- Automatically happens during plan, apply, and destroy.
- You can manually run:
terraform apply -refresh-only

To disable auto-refresh:
terraform apply -refresh=false
terraform destroy -refresh=false


TERRAFORM DEBUGGING
-------------------------
- Helps troubleshoot misconfigurations, dependency errors, etc.
- Set environment variables to capture detailed logs.

Commands:
export TF_LOG=TRACE
export TF_LOG_PATH="logs.txt"

Then:
terraform init
terraform plan


ALIAS & PROVIDERS
-------------------------
- Used to deploy resources in multiple AWS regions.
- We map resource blocks to specific provider blocks using aliases.

Example Code:

# Provider for us-east-1
provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "three" {
  ami           = "ami-0866a3c8686eaeeba"
  instance_type = "t2.micro"
  tags = {
    Name = "dev-server"
  }
}

# Provider for ap-south-1 with alias
provider "aws" {
  region = "ap-south-1"
  alias  = "south"
}

resource "aws_instance" "abcd" {
  provider      = aws.south
  ami           = "ami-08bf489a05e916bbd"
  instance_type = "t2.micro"
  tags = {
    Name = "dev-server"
  }
}



======================================25-09-2025==== Session 26========================================================


1. what is default backend: local
2. command to change the backend : terraform init -migrate-state
3. why to lock state file: to prevent from corruption
4. when state file will lock: when two people work on same state file parallely
5. does local backend support state lcoking: no
6. why use s3 : to lock state file automatically.


TERRAFORM STATE FILE
Terraform Stores the infrastructure infromation on state file.
it will automatically refreshed when we run plan, apply & destroy.
In Terraform, a backend is a configuration that determines how and where Terraform stores its state file and how it manages operations like apply, plan, and destroy.
 By default Terraform uses local backend. 
it stores state file in terraform.tfstate in local folder.
it stores information in json format.
if we delete any resource it stores infromation in terraform.tfstate.backup.


TERRAFORM STATE FILE LOCKING
in Real time once we complete our work we need to lock state file.
it ensures that only one operation can be executed at a time. 
once you lock state file you cant modify the infrastructure anymore.
When two people working on state file at a time it will be locked automatically.
unfortunately if two people runs apply at same time unpredictable results, like creating duplicate resources or destroying the wrong infrastructure.
Not all Terraform backends support locking.


Terraform used local backend to manage state file.
But in that local backend only one person can able to access it.
in Real time it’s often necessary to have a centralized, consistent, and secure storage mechanism for the state file. 
Amazon S3 is a popular choice for this, and when combined with DynamoDB for locking, it ensures safe, consistent operations.
TERRAFORM S3 BACKEND

ADVANTAGES
Global Access
Team Collaboration
Secure and Scalable
Centralized State Management
State File Versioning
Disaster Recovery

WHY LOCKING HAPPEND

when 2 developers  work on the same project with same state file then  the locking will be happend.
if state file is locked only first operation execute and second operation waits.
to remove state lock use: terraform force-unlock <LOCK_ID>
after adding dynamodb run:  terraform init -reconfigure

Add that block to existing code and run terraform init -upgrade
dynamodb -- > create table -- > Partition key: LockID -- > create
now after apply state file will go to s3 bucket
dev-1 type destroy and dev-2 type apply now state file locked.
you can check lock-id in new items of table.
once destroy done for dev-1 state file will be unlocked and dev-2 can work.

CODE:

provider "aws" {
  region = "us-east-1"
}

terraform {
  backend "s3" {
    bucket = "mybucket"
    key    = "path/to/my/key"
    region = "us-east-1"
    use_lockfile = true
  }
}

resource "aws_instance" "one" {
  ami           = "ami-0866a3c8686eaeeba"
  instance_type = "t2.micro"
  tags = {
    Name = "dev-server"
  }
}



MIGRATING FROM  S3 TO LOCAL BACKEND

if we want state file to back on local use below method.
remove backend code from main.tf 
run terraform init -migrate-state

CODE:

provider "aws" {
  region = "us-east-1"
}


resource "aws_instance" "one" {
  ami           = "ami-0866a3c8686eaeeba"
  instance_type = "t2.micro"
  tags = {
    Name = "dev-server"
  }
}


TERRAFORM REFRESH

This command will be use to refresh the state file.
terraform compares the current state to desired state, it it found any changes 
       on the current state it will update values to state file.
when we run plan, apply or destroy refresh will perform automatically.
if a server is manually created running terraform apply -refresh-only would detect those changes and update the state file to reflect the current state of the resource, but it won't attempt to change the infrastructure to match the Terraform configuration.
if you dont want to refresh while apply & destroy use 
        terraform apply/destroy -refresh=false


TERRAFORM BACKEND BLOCK

By default there is no backend configuration block within Terraform configuration Because Terraform will use it's default backend - local 
This is why we see the terraform.tfstate file in our working directory. 
FOR PARTIAL BACKEND: 
        path = "state_data/terraform.dev.tfstate"
FROM CLI: 
        terraform init -backend-config="path=state_data/terraform.prod.tfstate" -migrate-state
If want we can specify multiple partial backends too.

CODE:

provider "aws" {
  region = "us-east-1"
}

terraform {
  backend "local" {
    path = "/tmp/abc.tfstate"
  }
}


resource "aws_instance" "one" {
  ami           = "ami-0866a3c8686eaeeba"
  instance_type = "t2.micro"
  tags = {
    Name = "dev-server"
  }
}


TERRAFORM STATE COMMANDS

The terraform state command is used for advanced state management.
There are some cases where you may need to modify the Terraform state.
Rather than modify the state directly use these commands.
terraform state list : to list the resources
terraform state show aws_subnet.two : to show specific resource info
terraform state mv aws_subnet.two aws_subnet.three : to rename block
terraform state rm aws_subnet.three : to remove state information of a resource
terraform state pull : to pull state file info from backend


======================================26-09-2025==== Session 27========================================================
PROVIDER BLOCK:

By default provider plugins in terraform change version for every few weeks.
when we run init command, it download latest plugins always.
some code will not work with old plugins, so we need to update them.
To get latest provider plugins : https://registry.terraform.io/browse/providers.
when you add a new provider terraform init is must.
terraform providers: to list the providers which required to run code.
to create infra on any cloud all we need to have is provider.

TYPES:
1. OFFICIAL : MANAGED BY TERRAFORM
2. PARTNER  : MANAGE BY 3RD PATRY COMPANY
3. COMMUNITY: MANAGED BY INDIVIDUALS


CODE:

provider "aws" {
  region = "us-east-1"
}


terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
      version = ">5.70.0"
    }
  }
}


MULTI PROVIDERS:

terraform {
  required_version = ">=1.9.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">5.70.0"
    }
    azurerm = {
      source  = "hashicorp/azurerm"
      version = "4.9.0"
    }
    google = {
      source  = "hashicorp/google"
      version = "6.10.0"
    }
  }
}

TERRAFORM BLOCK:

This block is used to set global configurations and settings for the Terraform.
It usually includes details such as required providers, backend configuration, and version constraints.
terraform -v
terraform -version
terraform --version



TERRAFORM LOCAL BLOCK:

A local block is used to define  values.
if a value is repeating multiple times we can define it here.
This makes our code cleaner and easier to understand.
simply define value once and use for mutiple times.

CODE:

provider "aws" {
  region = "us-east-1"
}

locals {
env = "test"
}

resource "aws_vpc" "one" {
  cidr_block = "10.0.0.0/16"
  tags = {
    Name = "${local.env}-vpc"
  }
}

resource "aws_subnet" "two" {
  vpc_id     = aws_vpc.one.id
  cidr_block = "10.0.1.0/24"

  tags = {
    Name = "${local.env}-subent"
  }
}

resource "aws_instance" "three" {
  subnet_id     = aws_subnet.two.id
  ami           = "ami-0866a3c8686eaeeba"
  instance_type = "t2.micro"
  tags = {
    Name = "${local.env}--server"
  }
}


TERRAFORM COMMENTS:
We use comments to make others code to understand easily.
Terraform supports three different syntaxes for comments.
#   -- > single line comment
//  -- > single line comment
/*   */  -- > multi line comment
Note: if we put comments for code, terraform thinks code is not existed and it will destroy the resource.

TLS PROVIDER:

it provides utilities for working with Transport Layer Security keys & certificates. 
It provides resources that allow private keys, certificates & CSR.
Add tls on your own and try this below code.

CODE:

provider "aws" {
  region = "us-east-1"
}

resource "tls_private_key" "rsa-4096-example" {
  algorithm = "RSA"
  rsa_bits  = 4096
}


resource "local_file" "private_key_pem" {
  content  = tls_private_key.rsa-4096-example.private_key_pem
  filename = "devops.pem"
}



======================================27-09-2025==== Session 28========================================================

TERRAFORM VARIABLES

Terraform variables are values which we can change without editing the whole Terraform code every time.
It makes your code reusable (same code, different ENV— dev, test, prod)
It makesyour code clean (no hardcoded values)
It makes it flexible (you can pass values at runtime)

TERRAFORM VARIABLES TYPE:
Input Variables     : Values Given By the user 
Output Variables    : Values Given By the Terraform
Local Variables     : Temporary variables within Terraform

DATA TYPES:

Type	Description			Example
=================================================================
string	Text value			"""dev"", ""us-east-1"""
number	Numeric value			"2, 300"
bool	True or False			"true, false"
list	Ordered collection of values	"[""t2.micro"", ""t3.micro""]"
map	Key-value pairs			"{ env = ""dev"", tier = ""1"" }"
object	Group of named attributes	"{ name = ""app"", size = 2 }"
tuple	Ordered list of diff data types	"[""app"", 2, true]"


STRING & NUMBER:

provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "raham" {
  count         = var.instance_count
  ami           = "ami-04aa00acb1165b32a"
  instance_type = var.instance_type
  tags = {
    Name = "Raham"
  }
}

variable "instance_count" {
default = 3
}

variable "instance_type" {
default = "t2.micro"
}



LIST:

Main.tf

provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "one" {
  count         = length(var.instance_type)
  ami           = "ami-0de716d6197524dd9" # Example AMI ID, replace with a valid one
  instance_type = var.instance_type[count.index]
  tags = {
    Name = var.instance_name[count.index]
  }
}



Varibale.tf

variable "instance_type" {
  type    = list(string)
  default = ["t2.micro", "t2.small", "t2.medium", "t2.large"]
}

variable "instance_name" {
  type    = list(string)
  default = ["dev-server", "test-server", "uat-server", "prod-server"]

}


MAP:

Main.tf

provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "one" {
  ami           = "ami-0de716d6197524dd9" # Example AMI ID, replace with a valid one
  instance_type = "t2.micro"              # Default instance type, can be overridden
  tags          = var.tags
}


Varibale.tf

variable "tags" {
  type = map(string)
  default = {
    Name        = "MyInstance"  # Default tag value, can be overridden
    Environment = "Development" # Example additional tag
    Client      = "TCS"
  }
}

TERRAFORM TFVARS:

When we have multiple configurations for terraform to create resource
we use tfvars to store different configurations.
Pass the tfvars  While apply Command to take the values of that file.
NOTE: BY DEFAULT TERRAFORM WILL PICK VALUES FROM TERRAFORM.TFVARS 
if you don't pass any tfvars files terraform will pick values from terraform.tfvars.
ALTERNATE NAME: terraform.tfvars.json

ALTERNATE NAME:
terraform.tfvars.json

cat main.tf.   
provider "aws" {
region = "us-east-1"
}

resource "aws_instance" "one" {
count = var.instance_count
ami = "ami-0e001c9271cf7f3b9"
instance_type = var.instance_type
tags = {
Name = var.instance_name
}
}

cat variable.tf
variable "instance_count" {
}

variable "instance_type" {
}

variable "instance_name" {
}

cat dev.tfvars
instance_count = 1

instance_type = "t2.micro"

instance_name = "dev-server"

cat test.tfvars
instance_count = 2

instance_type = "t2.medium"

instance_name = "test-server"

cat variable.tfvars
instance_count = 3

instance_type = "t2.large"

instance_name = "prod-server"

terraform apply -auto-approve -var-file="dev.tfvars"
terraform apply -auto-approve -var-file="test.tfvars"
terraform apply -auto-approve -var-file="prod.tfvars"

TERRAFORM CLI

METHOD-1:
terraform apply --auto-approve
terraform destroy --auto-approve

METHOD-2:
terraform apply --auto-approve -var="instance_type=t2.micro" 
terraform destroy --auto-approve -var="instance_type=t2.micro"

NOTE: If you want to pass single variable from cli you can use -var 
form multiple variables from cli create terraform .tfvars files and use -var-file.

env variables:

A Terraform environment variable is a key-value pair set within the environment where Terraform is running.

LINUX & MAC:
export TF_VAR_region=us-east-1
export TF_VAR_instance_type='{ "t2.micro", "t2.medium" }'
export TF_VAR_tagmap='{ Environment = "dev", Project = "demo" }'   
WINDOWS:
$env:TF_VAR_instance_type = "t2.micro"
$env:TF_VAR_instance_count = 1
$env:TF_VAR_instance_name = "abcd"


VARIABLE PRECEDENCE

DEFINES THE LEVEL PRIORITY FOR VARIABLES IN TERRAFORM
TERRAFORM WILL PICK THE VARIABLES BY BELOW ORDER

        1. CLI
        2. AUTO.TFVARS
        3. TERRAFORM.TFVARS.JSON
        4. TERRAFORM.TFVARS
        5. ENV VARIABLE
        6. VARIABLE.TF


======================================06-10-2025==== Session 29========================================================


WORKSPACES:
Terraform workspaces allow you to maintain multiple environments 
       (e.g., development, testing, production) 
using the same Terraform configuration but with different states. 
Each workspace has its own state file (terraform.tfstate.d folder)
 resources created/managed in one workspace do not affect other workspaces.
the default workspace in Terraform  is default 
Each workspace is isloated (seperated with each other)




terraform workspace list : to list the workspaces
terraform workspace new dev : to create workspace
terraform workspace show : to show current workspace
terraform workspace select dev : to switch to dev workspace
terraform workspace delete dev : to delete dev workspace


    NOTE:
       1. we need to empty the workspace before delete
       2. we cant delete current workspace, we can switch and delete
       3. we cant delete default workspace


EXECUTION:
NOTE: TAKE CODES FROM TFVARS CONCEPT.


terraform workspace new dev
terraform apply -auto-approve -var-file="dev.tfvars"


terraform workspace new test
terraform apply -auto-approve -var-file="test.tfvars"


terraform workspace new prod
terraform apply -auto-approve -var-file="prod.tfvars"




FOR DELETION:


terraform destroy -auto-approve -var-file="prod.tfvars"
this command is used to go other workspace use this comand==> terraform workspace select test
terraform workspace delete prod


terraform destroy -auto-approve -var-file="test.tfvars"
terraform workspace select dev
terraform workspace delete test


terraform destroy -auto-approve -var-file="dev.tfvars"
terraform workspace select default
terraform workspace delete dev




TERRAFORM CLI: 


cat main.tf
provider "aws" {
}


resource "aws_instance" "one" {
count = var.var.instance_name
ami = "ami-00b8917ae86a424c9"
instance_type = var.instance_type
tags = {
Name = var.instance_name
}
}


cat variable.tf
variable "instance_count" {
}


variable "instance_type" {
}




variable "instance_name" {
}




METHOD-1:
terraform apply --auto-approve
terraform destroy --auto-approve


METHOD-2:
terraform apply --auto-approve -var="instance_type=t2.micro" 
terraform destroy --auto-approve -var="instance_type=t2.micro"


NOTE: If you want to pass single variable from cli you can use -var or if you want to pass multiple variables from cli create terraform .tfvars files and use -var-file.




TERRAFORM ENV VARS:


A Terraform environment variable is a key-value pair set within the environment where Terraform is running.
Used  to specify the location of the Terraform configuration files, set provider credentials, or define backend configurations.


LINUX & MAC:
export TF_VAR_region=us-east-1
export TF_VAR_instance_type='{ "t2.micro", "t2.medium" }'
export TF_VAR_tagmap='{ Environment = "dev", Project = "demo" }'   


WINDOWS:
$env:TF_VAR_instance_type = "t2.micro"
$env:TF_VAR_instance_count = 1
$env:TF_VAR_instance_name = "abcd"




DYNAMIC BLOCK:
it is used to reduce the length of code and used for reusabilty of code in loop.




provider "aws" {
  region = "us-east-1"
}


locals {
  ingress_rules = [{ port = 443 }, { port = 80 }, { port = 22 }]
}




resource "aws_security_group" "allow_tls" {
  name        = "terra sg"
  description = "Allow TLS inbound traffic"


  dynamic "ingress" {
    for_each = local.ingress_rules
    content {
      description = "*"
      from_port   = ingress.value.port
      to_port     = ingress.value.port
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }
  }


  tags = {
    Name = "terra sg"
  }
}




=======================================session 30 =======07-10-2025=============================================


MODULES:
it divides the code into folder structure.
Modules are group of multiple resources that are used together.
This makes your code easier to read and reusable across your organization.
we can publish modules for others to use.
each module will be having sperate plugins.
modules plugins will be store on .terraform/modules/

TYPES:
Root Module: This is the main  directory where Terraform commands are run. 
All Terraform configurations belong to the root module.

Child Modules: These modules are called by other modules.

yum install tree -y

.
├── main.tf
├── modules
│   ├── my_instance
│   │   └── main.tf
│   ├── s3_module
│   │   └── main.tf
│   └── vpc_module
│       └── main.tf

CODE:

cat main.tf

provider "aws" {
  region = "us-east-1"
}


module "vpc" {
  source = "./modules/vpc_module"
}

module "ec2" {
  source = "./modules/my_instance"
}

module "s3" {
  source = "./modules/s3_module"
}


mkdir -p modules/my_instance/
vim modules/my_instance/main.tf
resource "aws_instance" "one" {
  ami           = "ami-0ddc798b3f1a5117e"
  instance_type = "t2.micro"
  tags = {
    Name = "module-server"
  }
}


modules/s3_module/
vim modules/s3_module/main.tf
resource "aws_s3_bucket" "example" {
  bucket = "rahamdemo-tf-test-bucket"
}

cat modules/vpc_module/main.tf
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
  tags = {
    Name = "module-vpc"
  }
}

MODULE INPUT & OUTPUTS:
We can add Input and Output Blocks for Terraform Modules 
Root module can refer both variables & values of child modules.
Child modules cant refer variables, but it can refer its values.


├── main.tf
├── modules
│   └── myec2
│       ├── main.tf
│       ├── output.tf
│       └── variable.tf


cat main.tf
provider "aws" {
region = "us-east-1"
}

module "server" {
source = "./modules/myec2"
}

output "module_output" {
value = module.server.public_ip
}


cat modules/myec2/main.tf
resource "aws_instance" "one" {
  ami           = var.ami
  instance_type = var.instance_type
  tags = {
    Name = var.instance_name
  }
}

cat modules/myec2/variable.tf
variable "ami" {
  default = "ami-0ddc798b3f1a5117e"
}

variable "instance_type" {
  default = "t2.micro"
}

variable "instance_name" {
  default = "module-server"
}

cat modules/myec2/output.tf
output "public_ip" {
  value = aws_instance.one.public_ip
}


PUBLIC MODULES:

The module must be on GitHub and must be a public repo.
NAMING FORMAT: terraform-<provider>-<name> (terraform-aws-ec2-instance)
must have a description.
 module structure will be main.tf, variables.tf, outputs.tf.
x.y.z tags for releases.


==>>>>> VVIMP==> TERRAFORM GRAPH:
==>>>>> VVIMP ==> terraform use dot engine to show graph

:- it shows the resource relationships between objects in a Terraform configuration.
:- using the DOT language.
:- once create infra run the command: terraform graph
:- Go to Google -- > Graphwiz online & copy paste the code

CODE:

provider "aws" {
region = "us-east-1"
}

resource "aws_vpc" "one" {
  cidr_block = "10.0.0.0/16"
  tags = {
    Name = "dev-vpc"
  }
}

resource "aws_subnet" "two" {
  vpc_id     = aws_vpc.one.id
  cidr_block = "10.0.1.0/24"

  tags = {
    Name = "dev-subent"
  }
}

resource "aws_instance" "three" {
  subnet_id     = aws_subnet.two.id
  ami           = "ami-0866a3c8686eaeeba"
  instance_type = "t2.micro"
  tags = {
    Name = "dev-server"
  }
}

NAME: Graphwiz online


EXAM PATTREN:

CHAPTERS	: 9 
TYPE		: MCQ
MODE		: ONLINE (PROCTURED)
FEE		: 70 $

TOTAL Q.NO	: 57
PASS		: 70% (40)
MY QUESTIONS	: 50
TIME		: 60 MINS
VALIDITY	: 2 YEARS
RESULT		: NEXT MIN 



=================================session 31 =======08-10-2025=======================================================

HCP CLOUD:

HCP means HashiCorp Cloud Platform  
it is a managed platform to automate cloud infrastructure.
it provide privacy, security and isloation.
it supports multiple providers like AWS, Azure, and Google Cloud. 
it offers a suite of open-source tools for managing infrastructure, including Terraform, Vault, Consul, and Nomad. 
We can use Different Code Repos for a Project.
We can use Variable sets to apply same variables to all the workspaces.

ACCOUNT CREATION:

ACCONT-1: GITHUB -- > TO STORE CODE
CREATE A GITHUB ACCOUNT (https://github.com/ -- > singup -- > username,password,email)
create repo -- > name -- > create -- > add new file -- > write terraform code -- >  commit


ACCONT-2: HCP

Go to google & type : HCP CLOUD ACCOUNT SIGNIN
COTINUE WITH GITHUB
AUHORIZE
CLICK CHECK BOXES -- > CONTINUE

CREATE AN ORGINIZATION
CLICK ON TERRAFORM
CONTINUE TO HCP
CONTINUE WITH HCP ACCOUNT

CREATE ORG : NAME: SWIGGY
TYPE: PERSONAL

CREATE YOUR WORKSPACE
Version Control Workflow
INTEGRATE YOUR VCS  -- > GITHUB -- > SELECET REPO -- > NEXT -- > CONTINUE TO WORKSPACE
CONFIGURE VARAIBLES -- > ADD VARIABLE

AWS_ACCESS_KEY_ID : VALUE: Environment variable -- >  SENSITIVE -- > SAVE 
AWS_SECRET_ACCESS_KEY: Environment variable -- > SENSITIVE -- > SAVE 
NOTE: MARK THEM AS ENV VARIBALE AND MAKE SURE NO SPACES ARE GIVEN

RUNS -- > NEW RUN -- > START  -- > confirm and apply
IT WILL AUTOMATICALLY PLAN & WE NEED TO APPLY BY MANUAL
SECOND TIME WHEN WE CHANGE CODE IT WILL AUTOMATICALLY PLAN  
PLAN & APPLY
DESTROY

Cost Estimation policy:
Cost Estimation policy: we can estimate the cost of infra before we create it.
by default this feature is disable, we need to enable 
click on terraform logo --  > orginization -- > settings -- > Cost Estimation -- > enable


SENTINEL POLICY: ITS A POLICY AS A CODE.
BY THIS SENTINEL POLICY WE CAN WRITE OUR OWN CONDITIONS.
IT WILL CHECK THE CONDITION OF RESOURCE BEFORE IT CREATED.
IF CONDITION IS SATISFIED IT WILL CREATE RESOURE, OTHERWISE IT WONT.
EX: TAGS, VERIFIED AMIS, SG --

TERRAFORM LOGO -- > ORG -- > SETTINGS -- > POLICY 

IMP====>sentinel=> is used only for terraform security rile
IMP====> Open Policy Agent=> is used only for terraform , k8s, gitlab, etc security rile

TERRAFORM CLOUD FEATURES:
1. Workspaces
2. Projects
3. Runs
4. Variables and Variable Sets
5. Policies and Policy Sets
6. Run Tasks
7. Single Sign-On (SSO)
8. Remote State
9. Private Registry
10. Agents
11. Role-Based Access Control
12. Version Control Integration
13. Observability

TERRAFORM CLOUD ENTERPISE FEATURES:
Private Module Registry: Includes a private registry for sharing modules securely across teams.
Policy as Code: Integrates Sentinel for enforcing policies during provisioning.
Enhanced Automation: Offers advanced run triggers, notifications, and support for custom workflows.

Multi-Organization Support: Allows multiple teams or departments to manage their own infrastructure within a single account.
Advanced Collaboration: Provides role-based access controls and team management features, allowing for fine-grained permissions.
Enhanced Security: Features like SSO (Single Sign-On), audit logs, and compliance tools.

TO DELETE RESOURCES:
SETTINGS -- > DESTRUCTION AND DELETION -- > DELETE QUEUE

Cost Estimation policy:
Cost Estimation policy: we can estimate the cost of infra before we create it.
by default this feature is disable, we need to enable 
click on terraform logo --  > orginization -- > settings -- > Cost Estimation -- > enable


SENTINEL POLICY: ITS A POLICY AS A CODE.
BY THIS SENTINEL POLICY WE CAN WRITE OUR OWN CONDITIONS.
IT WILL CHECK THE CONDITION OF RESOURCE BEFORE IT CREATED.
IF CONDITION IS SATISFIED IT WILL CREATE RESOURE, OTHERWISE IT WONT.
EX: TAGS, VERIFIED AMIS, SG --
click on terraform logo --  > orginization -- > settings -- > Policy -- > name: Hard


POLICY: NOE: TAKE POLICY FORM OFFICAL DOCS OR CHATGPT

# Enforce that all resources must have tag "Env" set to "Prod"

import "tfplan/v2" as tfplan

# Function to check tags
validate_tags = func(resource) {
    # Some resources may not support tags
    if not ("tags" in resource.applied) {
        return true
    }

    # Check if "Env" tag exists and equals "Prod"
    return resource.applied.tags["Env"] is "Prod"
}

# Collect all resources from the plan
resources = filter tfplan.resource_changes as _, rc {
    rc.mode is "managed" and rc.type is not null
}

# Run validation
all_tags_valid = all resources as _, rc {
    validate_tags(rc)
}

# Main Rule
main = rule {
    all_tags_valid
}


STEP-1: POLICY -- > NAME -- > HARD -- >  CODE -- > CREATE 
STEP-2: POLICTY SET -- > CONNECT TO POLICY SET -- > NAME -- > SELECT POLICY -- > SAVE

TERRAFORM LOGO -- > ORG -- > SETTINGS -- > POLICY 
TERRAFORM CLOUD FEATURES:
1. Workspaces
2. Projects
3. Runs
4. Variables and Variable Sets
5. Policies and Policy Sets
6. Run Tasks
7. Single Sign-On (SSO)
8. Remote State
9. Private Registry
10. Agents
11. Role-Based Access Control
12. Version Control Integration
13. Observability

vvimp====> TERRAFORM CLOUD ENTERPISE FEATURES:
Private Module Registry: Includes a private registry for sharing modules securely across teams.
Policy as Code: Integrates Sentinel for enforcing policies during provisioning.
Enhanced Automation: Offers advanced run triggers, notifications, and support for custom workflows.

Multi-Organization Support: Allows multiple teams or departments to manage their own infrastructure within a single account.
Advanced Collaboration: Provides role-based access controls and team management features, allowing for fine-grained permissions.
Enhanced Security: Features like SSO (Single Sign-On), audit logs, and compliance tools.

TO DELETE RESOURCES:
SETTINGS -- > DESTRUCTION AND DELETION -- > DELETE QUEUE



OPA is a more flexible, open-source policy engine that works across a much broader cloud-native stack – Terraform, Kubernetes, APIs, and more. Sentinel, on the other hand, is developed by HashiCorp and is tightly coupled with Terraform and the HashiCorp ecosystem.

REMOTE ENHANCED BACKEND:
CREATE THIS 	FILE ON LOCAL:

provider "aws" {
region = "us-east-1"
}

terraform {
  backend "remote" {
    hostname = "app.terraform.io"
    organization = "my-terraform-batch-001"

    workspaces {
      name = "muthurepo"
    }
  }
}

resource "aws_instance" "three" {
  count         = 1
  ami           = "ami-00ca32bbc84273381"
  instance_type = "t2.micro"

  tags = {
    Name = "dev-server"
  }
}

COMMANDS:

terraform login
add token
terraform init
terraform plan


====================================session 32=======09-10-2025 ==========================================================

DYNAMIC BLOCK:
it is used to reduce the length of code and used for reusability of code in loop.


provider "aws" {
  region = "us-east-1"
}

locals {
  ingress_rules = [{ port = 443 }, { port = 80 }, { port = 22 }]
}


resource "aws_security_group" "allow_tls" {
  name        = "terra sg"
  description = "Allow TLS inbound traffic"

  dynamic "ingress" {
    for_each = local.ingress_rules
    content {
      description = "*"
      from_port   = ingress.value.port
      to_port     = ingress.value.port
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }
  }

  tags = {
    Name = "terra sg"
  }
}

TERRAFORM FUNCTIONS

you can call Functions from within expressions to transform and combine values.
Functions will start with braches () and values will be seperated by commas ,
terraform console is the command to work with functions
Types of functions: String, Number, Filesystem, Collection and Encoding


Secure Secrets in Terraform CodE

TIP 1: Do Not Store Secrets in Plain Text
TIP 2: Mark Variables as Sensitive
TIP 3: Environment Variables
TIP 4: Secret Stores (e.g., Vault, AWS Secrets manager)

NOTE: Even after marked a value as sensitive in tf file, they are stored within the Terraform state file. 
It is recommended to store security creds outside of terraform.


https://github.com/devenes/HashiCorp-Certified-Terraform-Associate?tab=readme-ov-file
============================================================================

================================================================================




OPENTOFU: 
its a Forked version of terraform.
it comes into market on 2023.


TERRAFORM is FREE & NOT-OPEN SOURCE & OPENTOFU is FREE & OPEN SOURCE.
TERRAFORM IS MAINTAINED BY IBM BUT OPEN TOFU MAINTED BY COMMUNITY.
TERRAFORM HAS LOT OF PROVIDERS & PLUGINS, BUT OPEN TOFU HAVING LIMTED.
TERRAFORM HAS MORE FEATURES, OPENTOFU HAS LESS FEATURES. 
TERRAFORM HAS HCP, BUT OPENTOFU DONT HAVE ANY CLOUD.




wget https://github.com/opentofu/opentofu/releases/download/v1.9.0-rc2/tofu_1.9.0-rc2_linux_amd64.zip
unzip tofu_1.9.0-rc2_linux_amd64.zip 
mv tofu /usr/local/bin/tofu 
tofu version


AFTER INSTALLNG OPENTOFU RUN THE FOLLOWING COMMAND:


vim /root/.bashrc
export PATH=$PATH:/usr/local/bin/
:wq
source /root/.bashrc




resource "aws_instance" "one" {
  ami           = "ami-0208b77a23d891325"
  instance_type = "t2.micro"
  tags = {
    Name = "raham-server"
  }
}




tofu init
tofu plan
tofu apply
tofu destroy


====================================session 33=======10-10-2025 ==========================================================


TERRAFORMER:
-: Terraformer is an open-source CLI tool that automatically generates Terraform code (HCL/JSON) from your existing cloud infrastructure.

==> What Terraformer does

- Scans your existing cloud infrastructure
- Generates Terraform .tf files, variables, and provider configuration
- Automatically imports resources into Terraform state
- Saves a lot of manual work (no need to write Terraform code from scratch)

STEP-1: INSTALL TERRAFORM


sudo yum install -y yum-utils shadow-utils
sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
sudo yum -y install terraform
aws configure


STEP-2: INSTALLING TERRAFORMER 


wget https://github.com/GoogleCloudPlatform/terraformer/releases/download/0.8.24/terraformer-all-linux-amd64
chmod +x terraformer-all-linux-amd64
sudo mv terraformer-all-linux-amd64 /usr/local/bin/terraformer
echo "export PATH=$PATH:/usr/local/bin/" >> .bashrc
source .bashrc


terraformer --version




STEP-3: IMPORTING EXISTING INFRA TO TERRAFORM


vi main.tf
provider "aws" {
region = "us-east-1"
}


terraform init


COMMAND: terraformer import aws --resources=sg,ec2_instance,elb --regions=us-east-1
UPDATE PROVIDERS IN STATE FILE:
terraform state replace-provider -- -/aws hashicorp/aws
terraform init
terraform plan
terraform apply




TERRASCAN
Terrascan is a open-source static code analysis tool.
It is designed for scanning infrastructure as code (IaC) templates and configurations. 
It helps identify security vulnerabilities and compliance violations
it provides best practices, security standards, and compliance requirements. 
It can also be used in pipelines with CI/CD systems




ADVANTAGES
Terrascan can be Integrated into CI/CD pipelines, IDEs and deployment workflows.
Terrascan provides a library of predefined security and compliance rules.
It can be set up to regularly scan and check for any drifts.
Generates detailed reports that highlight issues found during the analysis.
Supports mutiple cloud providers (AWS, Azure, GCP) cross-cloud infrastructure.
Tools  K8S, ArgoCD, Atlantis, GitHub, and Docker, making it versatile for
ADVANTAGES




commands
curl -L "$(curl -s https://api.github.com/repos/tenable/terrascan/releases/latest | grep -o -E "https://.+?_Linux_x86_64.tar.gz")" > terrascan.tar.gz
tar -xf terrascan.tar.gz terrascan && rm terrascan.tar.gz
install terrascan /usr/local/bin && rm terrascan
sudo install terrascan /usr/local/bin
installation
terrascan init
terrascan scan
commands




NORMAL CODE


provider "aws" {
  region = "us-east-1"
}


resource "aws_instance" "example" {
  ami           = "ami-0c55b159cbfafe1f0" 
  instance_type = "t3.micro"
  }
}






ENHANCED CODE


provider "aws" {
  region = "us-east-1"
}


resource "aws_instance" "example" {
  ami                      = "ami-0c55b159cbfafe1f0" 
  instance_type = "t3.micro"
  monitoring       = true
  metadata_options {
    http_endpoint = "disabled"            
  }


  tags = {
    Name = "IMDS-Disabled-Monitoring-Off"
  }
}


==================================================================================
STEP-1: UNDERSTAND THE ARCHITECTURE
STEP-2: WRITE THE CODE (in Real time code will be there)
STEP-3: CONFIGURE THE VALUES AS PER REQUIRMETS
STEP-4: USE HCP CLOUD TO DEPLOY INFRA


CODE  : https://github.com/devopsbyraham/new-infra-3-tier.git
NOTE  : PLESE FORK TO YOUR ACCOUNT (FORK=DOWLOAD IN GITHUB)
        REPLACE MY NAME devopsbyraham WITH YOUR GITHUB NAME 

========================================

TERRAFORM EXAM LINKS:
SESSION-0: https://forms.gle/bYHDf6F64iYAT7L79
SESSION-1: https://forms.gle/y5smbPT1AEhpLiWe6
SESSION-2: https://forms.gle/PwtHbEtxmt2VZhd26
SESSION-3: https://forms.gle/397HVSSTrhLaxvN38
SESSION-4: https://forms.gle/MkwhntHni4pmcoBi8
SESSION-5: https://forms.gle/cZzY75u6rc1aTwsr9
SESSION-6: https://forms.gle/6D45wWU6Tf7S1KhT9
SESSION-7: https://forms.gle/Ti51JbASmFyav2sK6
SESSION-8: https://forms.gle/3UXjTSoEMjLQFhf16
SESSION-9: https://forms.gle/pThJDwHku8xGEFKP9

DUMPS:
https://drive.google.com/drive/folders/1DWD3Cp0mSA1Ov-3faJxA-P8SbigpL9dn?usp=drive_link
