COURSE INTRO:
MULTI CLOUD DEVSECOPS WITH GENAI

CLOUDS: AWS, AZURE, GCP
DEVOPS
SECURITY
GEN AI

TOOL	: 25 TOOLS
AWS	: 25
AZURE	: 25
GCP	: 25

EXP	: 5 
CERTS	: 4

TIMINGS	: 9:00 AM TO 10:30 AM
DURATION: 5 months
FEE	: 16K 
REC	: 6K (6 MONTHS AFTER COURSE COMPLETION)
LINUX	: 30 FREE CLASSES

WHY DEVOPS ?
DELIVER THE PRODUCT/APP SPEEDILY.

WHO APPS ARE CREATED ?
USING SDLC 

SDLC: SOFTWARE DEVELOPMENT LIFE CYCLE
STAGES: 7

DEPLOY: INSTALLING APP TO SERVER

DEV:
PLAN
CODE
BUILD
TEST

OPS:
DEPLOY
OPERATE
MONITOR


WATERFALL MODEL: CLASSIC MODEL
WE CAN WORK ON STEP BY STEP PROCESS
IT CAN DO BOTH DEV AND TEST ACTIVITES ONE BY ONE.
IF CURRENT STAGE GONE WRONG WE CANT GO BACK TO PREVIOUS STAGE


AGILE MODEL:
WE WILL DELIVER THE APPLICATIO TO USERS INTO SMALLER PARTS
IT CAN DO BOTH DEV AND TEST ACTIVITES PARALLEY.


============================================================
WHAT IS CLOUD ?


PHYSICAL SERVER			CLOUD SERVER
-----------------------------------------------------
HIGH COST			LOW COST
ROOM & ELECTRICITY              DATA CENTERS
RESOURCE BUYING                 FREE RESOURCE
TIME TAKING                     LESS TIME TAKING


1. WITHOUT SERVER USER CANNOT USE APPLICATION.
2. CLOUD IS CHEAP AND FLEXIBLE.
3. PAY AS YOU GO


TYPES OF CLOUD COMPUTING:
1. PUBLIC CLOUD		: CLOUD THAT IS AVAILABE FOR ANY COMPANY
2. PRIVATE CLOUD	: CLOUD THAT IS AVAILABE FOR SOME COMPANY
3. HYBRID CLOUD		: PUBLIC CLOUD + PRIVATE CLOUD
4. COMMUNITY CLOUD	: MULTIPLE PEOPLE CAN USE SAME CLOUD RESOURCES

public cloud: aws, azure, gcp
private cloud: IBM, oracle, dell, tenecent
hybrid cloud: aws, IBM, dell, gcp -----


HOW TO USE CLOUD ?

AWS	: 6 MONTHS
AZURE	: 12 MONTHS
GCP	: 3 MONTHS


CLOUD COMPUTING: IT PROVIDE RESOURCES FROM THE INTERNET.
SERVERS, STORAGE, NETWORK, -----

=========================================================================================

APPLICATION: COLLECTION OF SERVICES
EX: WHATSPP, INSTAGRAM, YOUTUBE

SOFTWARE ARCHITECTURE: BULEPRINT OF APPLICATION

TYPES OF ARCHITECTURE:
1. ONE-TIER
2. TWO-TIER
3. THREE-TIER
4. N-TIER


WEB-SERVER:
AKA	: PRESENTATION LAYER
PURPOSE	: TO SHOW THE APP
WHO	: UI/UX (FRONTEND)
WHAT	: WEB TECHNOLOGIES
EX	: HTML, CSS, JS

APP-SERVER:
AKA	: BUSINESS/LOGIC LAYER
PURPOSE	: TO SHOW USE APP
WHO	: BACKEND DEVELOPERS
WHAT	: PROGRAMMING
EX	: JAVA, PYTHON, C, C++

DB-SERVER:
AKA	: DATA LAYER
PURPOSE	: TO STORE/RETRIVE DATA
WHO	: DBA/DBD
WHAT	: DB LANGAUGES
EX	: MYSQL, SQL, ORACLE, POSTGRES ----

===============================================================
SERVER: PROVIDES SERVICES TO USER/CLIENT.
ITS A VERY BIG COMPUTER.


=====================================================

website: https://killercoda.com/
select playground
select ubuntu


AMAZON: https://github.com/Ironhack-Archive/online-clone-amazon.git
INSTAGRAM: https://github.com/leocosta1/instagram-clone.git
WHATSAPP: https://github.com/hamsahmedansari/axiom-whatsapp-ui-homePage.git

apt update		: to show updates
apt install apache2 	: to install apache2
git clone https://github.com/Ironhack-Archive/online-clone-amazon.git
cd /var/www/html

#! /bin/bash
apt update		
apt install apache2 -y	
git clone https://github.com/Ironhack-Archive/online-clone-amazon.git
mv online-clone-amazon/* /var/www/html



vim /etc/nginx/nginx.conf

deny all;
systemctl restart nginx

======================================================================================================

AMI: AMAZON MACHINE IMAGE
PURPOSE: TO PROVIDE THE OPERATING SYSTEM, SOFTWARES TO SERVER
WHO: AWS CLOUD WILL GIVE AMI FOR ALL USERS
TYPES: FREE & PAID

CATEGORIES:
QUICK START    : AWS
MY AMI         : YOU
MARKET PLACE   : TO SELL OUR AMIS
COMMUNITY      : WE CAN USE OTHER PEOPLE AMI FOR FREE	



CREATE A SERVER AND LOGIN TO SERVER
sudo -i

#! /bin/bash
sudo -i
apt update		
apt install git apache2 -y	
git clone https://github.com/Ironhack-Archive/online-clone-amazon.git
mv online-clone-amazon/* /var/www/html


CREATING AMI
SELECT SERVER-1
CLICK ON ACTIONS
IMAGE AND TEMPLATES
CREATE IMAGE

IMAGE NAME: SWIGGY-IMAGE
DESCRIPTION: OPTINAL
SAVE

IT WILL TAKE FEW MINS TO MAKE AMI AVAILABLE

HOW TO MIGRATE SERVER :

SELECT AMI
ACTIONS
COPY AMI
DEST: MUMBAI
COPY

CREATE SERVER IN MUMBAI:

SELECT AMI
LAUNCH INSTANCE FROM AMI
CREATE INSTANCE
START SERVICE



HOW TO RECOVER DELETED AMI ?
Recycle Bin
Retention rules
Create retention rule
Retention rule name - rule01
Resource type: ami
Retention period: 7 
create retention rule

AMI -- > SELECT YOUR AMI -- > ACTIONS -- > DEREGISTER AMI
RECYCLE BIN -- > RESOURCES -- > SELECT AMI -- > RECOVER



EARNING-1: WHEN WE USE MORE SERVERS
AWS WILL BLOCK THE CPUS
WE NEED TO INCREASE QUOTAS

LEARNING-2: IF HTTPD SERVICE STOPPED APP WILL NOT RUN
systemctl start httpd
chkconfig httpd on  --- > this command make sure our service will stop


QUESTIONS: EXP
1. HOW DO YOU MIGRATE SERVER/APP FROM ONE REGION TO ANOTHER ?
A: CREATE AMI -- > COPY AMI TO OTHER REGION -- > CREATE SERVER FROM AMI

2. HOW DO YOU CREATE BACKUP FOR SERVER ?
A: CREATE AMI/SNAPSHOT

3. HOW TO RECOVER DELETED AMI ?
A: RECOVER FROM RECYCLE BIN (BY CREATING RETENTION RULE)

4. WHAT IS GOLDEN AMI ?
A: It contains the latest security patches, software, configuration for logging        and security performance.

===========================================================================================

STEP-1: CREATE A SERVER-1 AND LAUCH SWIGGY APP
STEP-2: CREATE A SERVER-2 AND LAUCH SWIGGY APP

WHAT IS HA ?
HIGH AVAILABILITY: MAINTANING MORE THAN ONE SERVER.

WHY TO USE HA ?
IF ONE SERVER GOT CRASHED SECOND SERVER WILL GIVE APPLICATION



54.89.69.33


NOTE: RUN THE BELOW SCRIPT ON USER DATA.
#! /bin/bash
sudo -i
apt update
apt install git nginx  -y
git clone https://github.com/karishma1521success/swiggy-clone.git
mv swiggy-clone/* /var/www/html/

CHANGING CODE: (NOT REQUIRED)
Connect to server
cd /var/www/html/
vim index.html
line number 40

NOTE: WITHOUT ELB USERS CAN GET APP FROM ONLY ONE SERVER
SO LOAD WILL NOT BE DISTRIBUTED
ULTIMATELTY THE SERVER-1 WILL BE CRASH AND USERS WONT GET ANY APP.

WHEN USERS ARE INCREASING LOAD IS INCREASING.
IF I DONT DISTRIBUTE THE LOAD THEN SERVER WILL BE CRASHED.
TO DISTRIBUTE THE LOAD WE NEED TO CREATE LOAD BALANCER.

WHY TO USE LOAD BALANCER IN REAL TIME:
TO DISTRIBUTE THE LOAD/TRAFFIC

TRAFFIC: INCOMMING REQUEST AND OUTGOING RESPONSE.


TYPES:
1. APPLICATION LOAD BALANCER (REAL TIME)
2. NETWORK  LOAD BALANCER
3. GATEWAY  LOAD BALANCER
4. CLASSIC  LOAD BALANCER


HTTP: HYPERTEXT TRANSFER PROTOCOL : 80
HTTPS: HYPERTEXT TRANSFER PROTOCOL SECURITY: 443

TARGET: SINGLE SERVER 
TARGET GROUP: MULTIPLE SERVERS SERVING SAME APPLICATION

PRACTICAL PART:
STEP-1: CREATE 2 SERVERS AND LAUCH SWIGGY APP
STEP-2: SELECT THE LOAD BALANCER
STEP-3: CREATE LOAD BALANCER -- > APPLICATION LOAD BALANCER
STEP-4: 
Load balancer name: swiggy
Scheme: Internet-facing
Load balancer IP address type: ipv4
Network mapping: select all Availability Zones
Security groups: select the sg with 80 & 443

STEP-5:
Crete target group 
Target group name: amazon-target-group
next
select 2 servers
include as pending below
create target group

Go back to previous tab and click on refresh
and finally click on create load balancer.

HOW TO AD NEW SERVER TO TARGET GROUP:
CREATE SERVER-3 AND DEPLOY SWIGGY APP
TARGET GROUP 
SELECT TARGET GROUP
ACTION
REGISTER TARGET 
include as pending below
Register pending target 

HOW TO ENABLE NEW AZ TO LB:
SELECT LB
NETWORK MAPPING
EDIT
SELECT 1-C SUBNET
SAVE


PROVISIONING MEANS CREATING.

TYPES OF ALOGRTHMS:
1. ROUND ROBIN (DEFAULT)
2. STICKY ROUND ROBIN
3. WEIGHTED
4. IP/URL
5. LEAST CONNECTIONS
6. LEAST TIME
7. RANDOM
8. LEAST BAND WIDTH

HOW TO CHANGE ALOGORITHMS:
SELECET TAGRGET GROUP -- > ATTRIBITES -- > Load balancing algorithm

IMP POINTS:
1. LB WORKS ON OSI MODEL.
2. LB DISTRIBUTE TRAFFIC ON ALOGRITHEMS.
3. DEAFULT ALOGORITHM FOR LB IS ROUND ROBIN.
4. TO CREATE A LB ATLEAST WE NEED TO HAVE 2 SERVERS.
5. IN REAL TIME SERVERS WILL AUTOMATIACLLY ADD TO LB.
6. TO CREATE LB WE NEED TO SELECT ATLEAST 2 AZ.

TYPES OF ROUTING:
1. HOST BASED ROUTING: www.train.paytm.com
2. PATH BASED ROUTING: www.paytm.com/movies, www.paytm.com/recharge

============================================================================


ASG = AUTO SCALING GROUP
WHY: TO ADD/REMOVE SERVERS AUTOMATICALLY.
IF WE DELETE A SERVER ASG WILL RECREATE SAME SERVER.

LOAD IS HIGH -- > ADD THE NEW SERVERS
LOAD IS LOW  -- > TO DELETE EXISTING SERVERS

WHEN WE USE AUTO SCALING GROUPS:
IF THE LOAD IS CHANGING FREQUENTLY WE CAN USE ASG.

TYPES OF SCALING:
1. HORIZONTAL SCALING : WE CREATE NEW SERVERS 
2. VERTICAL SCALING   : FOR EXISTING SERVERS WE CAN INCREASE CPU & RAM

WEB & APP : HORIZONTAL SCALING
DB        : VERTICAL SCALING

VERTICAL SCALING
1. STOP SERVER
2. ACTIONS -- > INSTANCE SETTINGS -- > CHANGE INSTANCE TYPE -- > t2.medium
3. START SERVER

TRACKING POLICY: USED TO SCALE THE SERVERS
1. CPU 
2. NETWORK IN
3. NETWORK OUT
4. COUNT PER TARGET


TEMPLATE: IT CONSIST OF CONFIGURATION OF A SERVER WHICH IS CREATED BY ASG.
WITHOUT TEMPLATE WE CANT CREATE ALL SERVERS WITH SAME CONFIG.

STEPS TO CREATE ASG:
AUTO SCALING GROUP -- > CREATE
NAME: SWIGGY
CREATE A LAUNCH TEMPLATE
NAME: SWIGGY-TEMPLATE
NOTE: GIVE THE CONFIGURATION JUST LIKE WE GIVE FOR EC2.
USE SCRIPT ON USERDATA

SCRIPT:
#! /bin/bash
sudo -i
apt update
apt install nginx  -y
cd /var/www/html/
git clone https://github.com/Ironhack-Archive/online-clone-amazon.git
mv online-clone-amazon/* .


CREATE TEMPLATE

AZ AND SUBNETS: US-EAST-1A, US-EAST-1B, US-EAST-1C -- NEXT
LOAD BALANCING: ATTACH TO A NEW LOAD BALANCER
INTERNET FACING
SELECT CREATE A NEW TARGET GROUP
NEXT

DESIRED : 2 -- > HOW MANY SERVERS YOU WANT NOW
MIN: 2 -- > ALWAYS ATLEAST I WANT 2 SERVERS
MAX: 10 -- > IF LOAD IS INCREASE I WANT 10 SERVERS

AUTOMATIC SCALING POLICY:
TARGET TRACKING SCALING POLICY:
CPU -- > VALUE: 50 -- > NEXT

http://internal-swiggy-1-1906495425.ap-south-1.elb.amazonaws.com/

NOTIFICATION -- > CREATE A TOPIC -- > NAME: SWIGGY SERVERS -- > EMAIL: give your email -- > NEXT -- > NEXT -- > CREATE AUTO SCALING GROUP
 

HOW TO INCREASE LOAD:

LOGIN TO SERVER:
apt update 
apt install stress -y 
stress
stress --cpu 8 --io 4 --vm 2 --vm-bytes 128M --timeout 500s


NOTE: TO DELETE SERVERS WE NEED TO DELETE ASG.
if you remove servers directly because of auto scaling group servers are going to recreate.

Q1. WHY WE NEED ASG ?
A: IF THE LOAD IS CHANGING FREQUENTLY WE CAN USE ASG.

Q2. TYPES OF ASG ?
A.  1. HORIZONTAL SCALING : WE CREATE NEW SERVERS 
    2. VERTICAL SCALING   : FOR EXISTING SERVERS WE CAN INCREASE CPU & RAM

Q3. HOW ASG IS GOING TO SCALE SERVERS ?
A. TRACKING POLICY: USED TO SCALE THE SERVERS
1. CPU 
2. NETWORK IN
3. NETWORK OUT
4. COUNT PER TARGET

Q4. HOW WILL ALL THE SERVERS IN ASG WILL GET SAME CONFIG ?
A. TEMPLATE

Q5. WHAT IS COOLING PERIOD ?
A. AMOUNT OF TIME TAKEN BY SERVER BEFORE DELETE WHEN LOAD IS DECREASED 

Q6. IF YOU DELETE A SERVER WILL ASG CREATE NEW SERVER ?
A. YES

Q7. WHAT IS WARMUP PERIOD ?
A. AMOUNT OF TIME TAKEN BY SERVER BEFORE LANUCHING IN ASG.

Q8. HOW WILL ASG KNOWS ABOUT CPU PERCENTAGE OF SERVER ?
A. USING CLOUD WATCH

=========================================================================
SESSION-13: CLOUD WATCH : 11-09-2025

CLOUD INFRA: COMBINATION OF HARDWARE & SOFTWARE 
RESOURCES USED TO RUN APP ON CLOUD.
EX: EC2, ELB, ASG, S3, VPC -----------

CLOUD WATCH: TO MONITOR THE CLOUD RESOURCE
NOTE:BY DEFAULT MONITORING FOR EC2 IS ENABLED

SERVER 		: APP
AMI		: COPY OF SERVER
ELB		: DISTRIBUTE LOAD BLW SERVERS
ASG		: CREATE SERVERS AUTOMATICALLY
CLOUD WATCH	: TO GET METRICS OF CLOUD RESOURCES

METRICS MEANS INFORMATION ABOUT SERVER.
METRIC		: CPU, RAM, DISK -------

TYPES OF DASHBOARDS:
1. CUSTOM : USERS WILL CREATE
2. AUTOMATIC: AWS WILL CREATE THE AUTOMATICALLY


STEP-1: CREATE EC2 AND DEPLOY THE APPLICATION

CREATE A SERVER AND RUN THE SCRIPT
SCRIPT:
#! /bin/bash
sudo -i
apt update
apt install nginx  -y
git clone https://github.com/karishma1521success/swiggy-clone.git
mv swiggy-clone/* /var/www/html/



STEP-2: CREAT A DASHBOARD
CLOUD WATCH:
CREATE DASHBOARD
NAME: DASHBOARD1
WIDGET: LINE
EC2
EC2: PER INSTANCE METRICS
GIVE ID OF YOUR SERVER
SELECT CPUUTILIZATION
CREATE WIDGET

TO GET MORE LOAD:
sudo -i
apt update
apt install stress -y
stress -c 4

EPEL: EXTRA PACKAGES FOR ENTERPRISE LINUX

GO TO DASHBOARD AND CLICK ON SHARE THE DASHBOARD
GENERATE A LINK AND COPY PASTE



HOW TO CREATE ALARM:

CLOUD WATCH 
ALL ALARM
CREATE ALARM
SELECT METRIC
EC2
EC2: PER INSTANCE METRICS
CPUUtilization
60 -- > NEXT
CREATE A SNS TOPIC -- > new topic -- > email
EC2 ACTION:STOP

=========================================================================
SESSION-14: IAM PART-1 : 11-09-2025


IAM: IDENTITY & ACCESS MANAGEMENT
WHY TO USE: TO PROVIDE PERMISSIONS AND RESTRICTIONS TO USERS IN AWS.


AUTHENTICATION : PERMISSION TO LOGIN
AUTHORIZATION  : PERMISSION TO WORK
POLICY: SET OF PERMISSIONS  (TOTAL 7)


IN REAL TIME WE DONT USE ROOT USER FOR ROUTINE WORKS
WE USE AWS IAM USER IN REAL TIME. (FOR DAILY WORKS)


IAM USER: 

IAM -- > USERS -- > CREATE USER -- > NAME: ABC -- > Provide user access to the AWS Management Console -- > I want to create an IAM user -- > Next -- > Attach policies directly -- > AmazonReadOnlyAccess -- > 

ADDING NEW PERMISSION:
IAM -- > USER -- > PERMISSION --> ADD PERMISSION 

IAM GROUP:
USED TO GIVE PERMISSION FOR MULTIPLE USERS.
A SINGLE USER CAN BE PART OF MAX 10 GROUPS.
GROUP CANNOT BE NESTED.
IF USER HAVE PERMISSION ON GROUP LEVEL AND USER LEVEL BOTH OF THE APPLIES.

create few users without permissions


IAM -- > USER GROUPS -- > NAME: DEVOPS -- > SELECT USERS -- > Attach policies directly -- > CREATE

IF U FROGOT USERNANE &PASSWORD:
SELECT USER -- > SECURITY CREDNTIALS -- > MANAGE CONSOLE ACCESS


IAM ROLES:
ROLES ARE USED BY SERVICES.
ROLE IS SIMLAR TO IAM USER.
ROLES ALSO HAVING PERMISSION LIKE USERS.
ROLE DOESNT HAVE ANY CREDS.
WE CAN SET TIME LIMIT FOR ROLES.
IF TWO SERVICES WANT TO COMMUNICATE OR WORK TOGETHER WE USE ROLES.
EX: EC2 -- > S3

http://54.242.59.171/

ROLE -- > CREATE ROLE -- > AWS SERVICE -- > EC2 -- > PERMISSIONS: S3 FULL ACCESS -- > NAME: S3 ROLE -- > CREATE

ATTACH ROLE TO SRVER:
SELECT SERVER -- > ACTIONS -- > SECURITY -- > MODIFY IAM ROLE -- > S3 ROLE -- > UPDATE

DEPLOY THE APP FROM SCRIPT 
GO TO SERVER

curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
apt install unzip -y
unzip awscliv2.zip
sudo ./aws/install


command: aws s3 ls -- > execute this on server
aws s3 cp /var/log/ngix/access.log s3:bucketname

REVOKE SESSION: TO REMOVE THE EXISTING PERMISSION OF A ROLE.

INLINE POLICY: CREATING CUSTOM POLICY FOR RESOURCES

USER -- > ADD PERMISSION -- > CREATE INLINE POLICY -- > SERVICE: S3 -- > All S3 actions (s3:*) -- > bucket: BUCKETNAME -- > next


Q1. DIFF BLW AUTHENTICATION VS AUTHORIZATION ?
A.  AUTHENTICATION : PERMISSION TO LOGIN
    AUTHORIZATION  : PERMISSION TO WORK

Q2. HOW TWO services COMMUNICATE WITH EACH OTHER ?
A   USING ROLES

Q3. CAN WE CREATE NESTED GROUPS IN AWS ?
A   NO

Q4. HOW MANY GROPUPS CAN A SINGLE USER CAN BE PART OF ?
A.  10

Q5. DIFF BLW IAM USER & ROLES >
A   USER WILL HAVE CREDS, ROLES WILL NOT HAVE
    USER WONT HAVE TIME LIMIT BY DEFAULT, ROLES WILL HAVE
    USER: USER -- SERVICE  ROLE: SERVICE -- SERVICE

Q6. CAN WE ATTACH MULTIPPLE ROLES TO USER ?
A    YES

Q7. HOW DO YOU RESTRICT A SPECIFIC PERMISSION TO USER ?
A. PERMISSION BOUNDARY

Q8. BY DEFAULT FOR A USER HOW MANY KEYS WE CAN CREATE ?
A. 2

Q9. IF YOU LOST YOUR KEYS WHAT YOU ARE GOING TO DO ?
A. DEACTIVE THE KEYS

Q10. I HAVE A SPECIAL BUCKET WHERE MY CUSTOMRE NEED TO ACCESS FILES HOW DO YOU PROVIDE PERMISSION TO THAT CUSTOMER ?
A. INLINE POLICY

Q11. WHAT IS THE POLICY FORMAT ?
A. JSON(JAVA SCRIPT OBJECT NOTATION)

===========================================================================
SESSION-15: IAM PART-2 : 12-09-2025

USER -- > KEYS (PERMISSIONS) -- > SERVER
ACCESS KEY & SECRET ACCESS KEY = USED TO ASSIGN PERMISSION TO SERVER
BY DEFAULT WE CAN CREATE ONLY 2 KEYS.
WHAT WILL YOU DO WHEN YOU LOST THE KEYS?
ANS: DEACTIVATE THE KEYS
NOTE: PLS DONT DELETE THEM WITHOUT DEACTIVATE

FLOW: USER -- > KEYS -- > ATTACH TO SERVER -- > SERVER

CREATE A USER WTH ADMIN ACCESS

CREATE A USER -- > SECURITY CREDENTIALS -- > CREATE ACCESS KEY -- > 
Command Line Interface (CLI)-- > create 


curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

aws configure -- > Run this command on server 

AWS Access Key ID [None]: *********************** [pls put your own keys :(]
AWS Secret Access Key [None]: ************************
Default region name [None]: ap-east-1
Default output format [None]: table


CLI -- > COMMAND LINE INTERFACE
WHY TO USE: TO OPERATE/CONTROL AWS SERVICES THROUGH COMMANDS

aws s3 ls 			: to list the buckets
aws s3 ls s3://bucketname	: to list files inside the bucket
aws s3 mb s3://newbucket	: to create a bucket
aws s3 rb s3://newbucket	: to delete a bucket
aws s3 cp file s3://bucket	: to copy file1 to bucket
aws s3 cp copy-s3-uri .		: to copy files from bucket to server
aws s3 sync s3://bucket1 s3://bucket2	: to copy all files from one bucket to another.

mkidr raham
touch raham/touch file{1..10}
aws s3 cp folder s3://bucket --recursive : to copy folder to bucket

IAM:
aws iam list-users		: TO LIST IAM USERS
aws iam list-groups		: TO LIST IAM GROUPS
aws iam list-roles		: TO LIST IAM ROLES

aws iam create-group --group-name devops
aws iam create-user --user-name rahamabc
aws iam create-role --role-name demorole

aws iam delete-group --group-name devops
aws iam delete-user --user-name rahamabc
aws iam delete-role --role-name demorole

EC2:

aws ec2 run-instances --image-id ami-05fcfb9614772f051 --instance-type t2.micro --count 1 
aws ec2 describe-instances   : to show complete info of all the servers
aws ec2 stop-instances --instance-ids i-054a200a4effc917c
aws ec2 start-instances --instance-ids i-054a200a4effc917c
aws ec2 terminate-instances --instance-ids i-054a200a4effc917c



CUSTOM PASSWORD POLICY:
IAM -- > Account Settings -- > Password policy -- > Edit -- > save

USER CREDS REPORT:
The credentials report lists all your IAM users in this account and the status of their various credentials. After a report is created, it is stored for up to four hours.

IAM
Credential Report

PERMISSION BOUNDARY: TO RESTRICT A USER TO NOT USE A SPECIFIC SERVICE.

==================================================================
DAY- 16: EFS : 13-09-2025



EFS: ELASTIC FILE SYSTEM
PURPOSE: TO SHARE DATA BLW TWO SERVERS
SIZE: GROW UP TO PETABYTES
TYPE: SERVER LESS
PROTOCOLS: NFSV4.0 & NFSV4.1

INTEGRATIONS: EC2, ECS, EKS, Lambda, Fargate.
MODES: 1. GENERAL PURPOSE 2. ELASTIC
PRICING: 5 GB/YEAR FREE
BACKUP: WE CAN GET BACKUPS



NOTE: IF NFS IS NOT ENABLE ON SG YOU CANT GET THE DATA.

EC2 -- > SECURITY GROUP -- > NAME -- > DESCRIPTION -- > SSH,NFS,HTTPD -- >
PUT ANYWHERE -- > SAVE

PRACTICAL PART:
STEP-1: CREATE EFS



EFS -- > CUSTOMIZE -- > NAME: REGIONAL  -- > REGIONAL -- > ELASTIC -- > GIVE SG WITH NFS ENABLE -- > NEXT -- > CREATE.


STEP-2: CREATE 2 SERVERS ON US-EAST-1 & US-EAST-1B


STEP-3: INSTALL APACHE AND GIT ON BOTH SERVERS

yum install httpd git -y
systemctl start httpd


STEP-4: ATTACH EFS TO BOTH SERVERS 

GO TO EFS -- > SELECT EFS -- > ATTACH -- > COPY PASTE COMMANDS ON BOTH SERVERS

sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-029cbfcc1807809c1.efs.us-east-1.amazonaws.com:/  /var/www/html/


STEP-5: UPLOAD THE CODE ON US-EAST-1A
git clone https://github.com/Ironhack-Archive/online-clone-amazon.git
mv online-clone-amazon/* /var/www/html


NOTE: 
WE CANT INTEGRATE EFS DIRECTLY TO ASG
CEATE A SERVER -- > CREATE AMI -- > ASG

====================================================================
DAY-17: ROUTE 53 : 15-09-2025

FIRST EVER DOMAIN NAME : https://symbolics.com/ -- > 1985


NAME RESOLUTION : PROCESS OF CONVERTING  IP TO DOMAIN (1.2.3.4 = WWW.SWIGGY.COM)
DNS: DOMAIN NAME SYSTEM : 53

ROUTE 53


DNS: DOMAIN NAME SYSTEM 
PORT: 53
PURPOSE: CONVERTING IP TO DOMAIN (192.168.1.0 = www.swiggy.com)
DOMAIN PROVIDERS: GODADDY, BIGROCK, HOSTINGER, AWS, --------

TYPES OF RECORDS:
A	: IPV4
AAAA	: IPV6
CNAME	: HOSTNAME --> HOSTNAME
MX	: MAIL SERVER


#! /bin/bash
sudo -i
apt update
apt install nginx  -y
cd /var/www/html/
git clone https://github.com/Ironhack-Archive/online-clone-amazon.git
mv online-clone-amazon/* .


NAME SERVER: IT TELLS BROWSER TO  CONNECT EXACT SERVER WHERE YOUR APP RUNS 
EX: GUIDE FOR A TOUR


PRACTICAL PART:
STEP-1: BUY A DOMAIN FROM DOMAIN FROM BELOW SITES (GODADDY,HOSTINGER, BIG ROCK)
STEP-2: CREATE A SERVER IN AWS AND LAUNCH AMAZON APP
STEP-3: GO TO ROUTE 53 -- > HOSTED ZONES -- > CREATE -- > GIVE DOMAIN -- > PUBLIC -- > CREATE
STEP-4: UPDATE NAME SERVER VALUES IN DOMAIN REGISTRAR (BIG ROC * : : K)
STEP-5: CREATE RECORD -- > GIVE IP -- > SAVE


NOW LETS CONVERT LOAD BALANCER DNS TO OUR OWN DNS
CREATE ONE MORE SERVER AND ATTACH BOTH SERVERS TO LOAD BALANCER


STEP-6: SELECT RECORD -- > EDIT --> ALIAS --> SELECT APP LB -- > REGION -- > SELECT LB -- > 

Routing policy
Simple (DEFAULT)
Weighted
Latency
GeoLocation
Multi vlue
IP based
FailOver

=====================================================================================================================================

DAY-18: CDN : 16-09-2025


CDN: CONTENT DELIVERY NETWORK
USED TO DELIVER APP FROM EDGE LOCATION
IT GIVES FAST RESPONSE 
EX: CRICKET MATCHES, E-COMMERCE SALES, ------

WE NEED TO CREATE ORIGIN
ORIGIN: FROM WHERE YOU ORIGINAL APPLICATION IS COMMING

EXAMPLE OF ORIGINS: S3, ELB, API GATEWAY

Origin Shield
Its an additional caching layer that can help reduce the load on your origin and help protect its availability.

ADVANTAGES:
1. REDUCE LATENCY
2. CUT COST
3. CUSTOMIZE DELIVERY
4. SECURITY

FREE TIER:
1 TB of data transfer out
10,000,000 HTTP or HTTPS requests
2,000,000 CloudFront Function invocations
Each month, always free


NOTE: FROM LB WE NEED TO ACCESS APP FROM HTTP NOT HTTPS

STEP-1: CREATE 2 SERVERS AND DEPLOY AMAZON APP
STEP-2: CREATE A LOAD BALANCER
SETP-3: CLOUD FRONT -- > NAME -- > SINGLE APP -- > NEXT -- > ORIGIN DOMAIN: ELB (SELECT YOUR LB) -- > Customize -- > Protocol: HTTP only (ORIGIN PROTOCOL)
-- > Enable Origin Shield: US-EAST-1  -- > Protocol: HTTPS(CLOUD FRONT PROTOCOL) -- > SELECT WAF -- > IPv6: OFF -- > CREATE

NOTE: IT WILL TAKE 2 MINS TO ACTIVATE 

HOW TO BLOCK USERS FROM DIFF LOCATIONS:
SECURITY -- > CloudFront geographic restrictions

MORE DATA: OPEN WAF



CLOUD TRAIL: IT WILL SHOW SERVICES ACCESSED BY USER
BY DEFAULT IT STORES LAST 90 DAYS OF ACTIVITIES.
$2.00 per 1,00,000 management events delivered.
$0.10 per 100,000 network activity events delivered

BY DEFAULT CLOUD TRAIL WILL RECORD ALL EVENTS
BUT I WANT ON SPECIFI EVENTS (S3, EC2) WE NEED TO CREATE CLOUD TRAIL 

Trail name: my-users-events
Log file SSE-KMS encryption: Disable
NEXT
Events: Management & Data
Resource: s3
Create trail

Q1. HOW DO YOU TRACK USERATVITIES IN AWS ?
A:  CLOUD TRAIL

Q2. ONE OF THE USER DELETED ON SERVER IN AWS ACCOUNT HOW DO YOU FIND THEM ?
A:  CLOUD TRAIL

Q3. BY DEFAULT HOW MANY DAYS EVENTS SHOULD BE STORED ?
A: 90 DAYS

Q4. CAN WE FILER EVENTS SEPERATELY FOR A RESOURCE ?
A: YES 


=============================================================================

DAY-19: EBS : 17-09-2025

MODIFIYING VOLUME:
SELECT SERVER -- > CLICK ON STORAGE -- > SELECT VOLUME -- > ACTIONS -- > MODIFY

ADDING ANOTHER VOLUME
CREATE A VOLUME
VOLUME -- > CREATE -- > SIZE: ABC -- > AZ: SELECT AS YOUR SERVER AZ -- > TAGS: Name = New server -- > CREATE

ATTACHING VOLUME TO SERVER:
SELECT VOLUME -- > ACTIONS -- > ATTACH -- > SELECT YOUR SERVER -- > /dev/xvdb -- > save

BOOT/ROOT VOL : WHICH HAS OS
NON-ROOT/DATA VOL: WHICH WILL NOT HAVE OS


SERVER MIGRATION:

1. CREATE A SERVER ON US-EAST-1A AND DEPLOY APP
USE MY AMAZON SCRIPT

2. TAKE A SNAPSHOT OF SERVER
SELECT SERVER -- > STORAGE -- > VOLUME -- > ACTIONS -- > CREATE SNAPSHOT -- > CREATE

3. COPYING THE SNAPSHOT:
SELECT SNAPSHOT -- > ACTIONS -- > COPY SNAPSHOT -- > DESTINATION: AP-SOUTH-1 -- > COPY

4. CREATE EBS FROM SNAPSHOT
SELECT SNAPHSOT -- > ACTIONS -- > CREATE A VOLUME -- > AZ: US-EAST-2B -- > CREATE

5. CREATE A SERVER ON AP-SOUTH-1 & DETACH EXISTING VOLUME
CREATE A SERVER -- > SELECT -- > STOP 
VOLUME -- > SELECT -- > ACTIONS -- > DETACH

6. ATTACH THE VOLUME CREATED FROM SNAPSHOT
VOLUME -- > ACTIONS -- > ATTACH -- > SELECT SERVER -- > DEVICENAME: FIRST OPTION -- > ATTACH


Q1. HOW DATA WILL BE STORED ON EC2 ?
A.  EBS

Q2. HOW TO TAKE SERVER BACKUP ?
A. SNAPSHOTS

Q3. ARE SNAPSHOTS & EBS REGION AND AZ SPECIFIC ?
A. YES

Q4. MIN AND MAX SIZE OF EBS ?
A.  8 GB - 16 TB

Q5. CAN WE ATTACH MULTIPLE EBS TO SERVERS AT A TIME ?
A.   YES

Q6. HOW TO SAVE COST OF SNAPSHOTS ?
A. ARCHIVE THEM (RECOVERY PERIOD IS 24 TO 72)

Q7. CAN WE ATTACH SNAPSHOT TO EC2 DIRECTLTY ?
A. NO

Q8. TYPES OF VOLUMES IN EBS ?
A.  SSD & HDD

AMI VS SNAPSHOTS:

FIRST TIME WE USE AMI TO LAUNCH SERVERS
SNAPSHOTS WE USE TO TAKE BACKUP DAILY.

1 -- > 10 files -- > ami
10 -- > 100 files -- > snapshot


aws ec2 create-snapshot --volume-id vol-1234567890abcdef0 


==================================================================================

DAY-20: RDS : 18-09-2025

RDS 
DATABASE
CREATE DATABASE
STANDARD
ENGINE: MYSQL
TEMPLATE: 3 INSTANCES
CREDS: AWS SECRET MANAGER
INSTANCE CONFIG: DB.M5.2XLARGE
CONNECT TO EC2: SELECT YOUR DB SERVER

INSTALL MYSQL IN AMAMZON LINUX:
sudo wget https://dev.mysql.com/get/mysql80-community-release-el9-1.noarch.rpm 
sudo dnf install mysql80-community-release-el9-1.noarch.rpm -y
sudo rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2023
sudo dnf install mysql-community-client -y
sudo dnf install mysql-community-server -y


INSTALLING ON UBUNTU:
sudo apt update
sudo apt install mysql-server -y
mysqld --version
sudo systemctl status mysql


AFTER CREATING DB TO GET THE CREDS

VIEW CREDS 
MANAGE CREDS
SECERET VALUE
REVEAL



CONNECTION  TO DATABASE:
DATABASE -- > CONNECTIVITY -- > END POINT 
database-1-instance-1.us-east-1.rds.amazonaws.com


NOW GO TO EC2 AND RUN BELOW COMMAND TO CONNECT
mysql -u admin -h endpoint -p

GETTING PASSWORD:
DATABASE -- > CONFIGUARTION -- > Master credentials ARN -- > Manage in Secrets Manager 
Retrieve secret value

create database raham;
show databases;
use raham;

CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(100),
    password VARCHAR(20),
    city VARCHAR(20),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INSERT INTO users (name, email, password, city) VALUES ('ramu', 'ramu@gmail.com', 'ramu123', 'rajavarm' );
INSERT INTO users (name, email, password, city) VALUES ('remo', 'remo@gmail.com', 'remo143', 'vizag');
INSERT INTO users (name, email, password, city) VALUES ('aparichith', 'aparichith@gmail.com', 'kumbipakam', 'hell');

SELECT * FROM users;
exit


======================================================================================================

DAY-21: RDS : 19-09-2025


WALL		: VPC
PUB-SUB		: HALL
MAIN GATE	: IGW

CIDR: CLASSLESS INTER DOMAIN ROUTING

VPC 	= WALL

STEP-1: CREATE VPC
VPC -- > CREATE VPC -- > NAME: SWIGGY -- > CIDR: 10.0.0.0/16 -- > CREATE

SUBNET = ROOM

STEP-2: CREATE SUBNET [PUBLIC = HALL]
SUBNET -- > CREATE -- > VPC: SWIGGY -- > NAME: WEB-SUBNET  -- > CIDR: 10.0.0.0/24 -- > CREATE

STEP-3: CREATE A INTERNET GATEWAY [IGW = MAIN GATE]
INTERNET GATEWAY -- > CREATE -- > NAME: SWIGGY-IGW -- > CREATE -- > ATTACH TO VPC -- > SWIGGY

STEP-4: CREATE ROUTE TABLE
ROUTE TABLE -- > NAME: SWIGGY-WEB-RTB -- > VPC: SWIGGY -- > CREATE
EDI ROUTES -- > ADD -- > 0.0.0.0/0 -- > IGW : SWIGGY -- > ADD

ASSOCIATE THE WEB SERVER TO THE ROUTE TABLE.
SUBNET ASSOCIATION -- > SELECT WEBSUBNET -- > ASSOCIATE.

CREATE  A WEB SERVER WITH SWIGGY VPC AND SWIGGY-WEB SUBNET.
NOTE: SELECT EDIT OPTION IN NETWORK
VPC	: SWIGGY
SUBNET	: SWIGY-WEB-SUBNET

NOTE: ENABLE AUTO ASSIGN PUBLIC IP FOR WEB SERVER WHILE CREATING.
CREATE NEW SG 

http://13.233.224.47/

#! /bin/bash
sudo -i
apt update
apt install git nginx  -y
cd /var/www/html/
git clone https://github.com/karishma1521success/swiggy-clone.git
mv swiggy-clone/* .



STEP-5: CREATE SUBNET (PRIVATE =APP = BED ROOM)
SUBNET -- > CREATE -- > VPC: SWIGGY -- > NAME: APP-SUBNET  -- > CIDR: 10.0.1.0/24 -- > CREATE

STEP-6: CREATE A NAT GATEWAY
NAT GATEWAY -- > CREATE -- > NAME: SWIGGY-NAT -- > SUBNET: WEB SUBNET -- > Elastic IP allocation -- > CREATE

STEP-7: CREATE ROUTE TABLE
ROUTE TABLE -- > NAME: APP-RTB -- > VPC: SWIGGY -- > CREATE
EDI ROUTES -- > ADD -- > 0.0.0.0/0 -- > NAT : SWIGGY -- > ADD
ASSOCIATE THE APP SERVER TO THE ROUTE TABLE.
SUBNET ASSOCIATION -- > SELECT APPSUBNET -- > ASSOCIATE.


CREATE  A APP SERVER WITH SWIGGY VPC AND SWIGGY-APP SUBNET.
NOTE: SELECT EDIT OPTION IN NETWORK
VPC	: SWIGGY
SUBNET	: SWIGY-APP-SUBNET

NOTE: DISABLE AUTO ASSIGN PUBLIC IP FOR APP SERVER WHILE CREATING.
CREATE NEW SG 

NOW CONNECTING TO APP SERVER:

OPEN WEB SERVER & sudo -i
vim pemfile -- > copy & paste the pem file content -- > chmod 400 pemfile
ssh "pemfile" ec2-user@public-ip 

PEERING: ESTABLISHING CONNECTION BLW 2 VPCS

TRANSIT GATEWAY:
networking service that allows you to connect multiple VPCs, on-premises networks, and other AWS resources through a central hub. 

VPC Endpoints: provide a secure and private connection between your VPC & AWS services, without requiring access over the public internet. 
This is useful for scenarios where you want to avoid exposing sensitive data to the internet while enabling private communication between resources in your VPC and services like Amazon S3, DynamoDB, or other AWS services.

=======================================================================================
CFT: CLOUD FORMATION TEMPLATE
WE CEATE RESOURCES THROUGH CODE
CODE:YAML/JSON
FEB 25 2011 
IAC : INFRA AS A CODE


YAML = YET ANOTHER MARKUP LANGUAGE
JSON = JAVA SCRIPT OBJECT NOTATION


NAME	: RAHAM
LOC 	: HYD
COMPANY	: NIT
PRO	: TECHIE
AGE	: *****

ADVANTAGES:
1. WRITE CODE FOR ONCE AND USE MULTIPLE TIMES
2. WE CAN SAVE TIME
3. WE CAN AVOID MANUAL WORK
4. WE CAN LIMIT THE MISTAKES

TEMPLATE: IT IS A FILE WHICH CONSIST OF RESOURCE INFROMATION.
STACK: GROUP OF RESOURCE

Specifying templates:
1. S3
2. LOCAL
3. GITHUB
4. BUILD COMPOSERS

STEPS FOR PRACTICAL PART:
1. SELECT CFT -- > Create Stack
2. Build from Infrastructure Composer
3. Drag and drop the ec2 resource and copy code from chatgpt
4. validate -- > create template -- > next
5. ROLE -- > CloudFormation -- > admin access -- > name -- > attach
6. CREATE SNS TOPIC FOR SENDING EMAIL.

PROMPT-1: SIMPLE PROMPT
generate a cft code for aws vpc  

PROMPT-2: HIGH LEVEL PROMPT
as an experienced cloud engineer generate a powerful cft script to create vpc subnet igw and routetable in a simplified way that need to have very less code

STATUS:
CREATION
DELETION
UPDATION
ROLLBACK: IF ONE RESOURCE IN STACK GOT FAILED, IT WILL DELETE ALL RESOURCES.

Resources:
  EC2Instance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: ami-020cba7c55df1f615
      InstanceType: t2.micro
      KeyName: Rkeypair
      SecurityGroups:
        - all
      Tags:
        - Key: Name
          Value: raham



CHANGE SET: it is created when we want to modify the existing resource configuration.
changeset
create changeset.

Edit in Infrastructure Composer
template
t2.medium=t2.large
validate
create changeset
next
next
next
submit
select changeset - > execute


VPC CODE:

AWSTemplateFormatVersion: '2010-09-09'
Description: Minimal VPC setup with subnet, IGW, and route table

Resources:

  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.10.0.0/16
      EnableDnsSupport: true
      EnableDnsHostnames: true
      Tags: [{ Key: Name, Value: MyMinimalVPC }]

  Subnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.10.1.0/24
      MapPublicIpOnLaunch: true
      Tags: [{ Key: Name, Value: PublicSubnet }]

  IGW:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags: [{ Key: Name, Value: IGW }]

  AttachIGW:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref VPC
      InternetGatewayId: !Ref IGW

  RouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags: [{ Key: Name, Value: PublicRouteTable }]

  DefaultRoute:
    Type: AWS::EC2::Route
    DependsOn: AttachIGW
    Properties:
      RouteTableId: !Ref RouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref IGW

  SubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref Subnet
      RouteTableId: !Ref RouteTable

Outputs:
  VPCId:
    Value: !Ref VPC
  SubnetId:
    Value: !Ref Subnet
  InternetGatewayId:
    Value: !Ref IGW


============================================================================================================================

TERRAFORM-DAY-1: 22-09-2025

INFRASTRUCTURE:
resources used to run our application on cloud.
ex: ec2, s3, elb, vpc, Asg --------------


in general we used to deploy infra on manual 

Manual:
1. time consume
2. Manual work
3. committing mistakes

Automate -- > Terraform -- > code -- > hcl (Hashicorp configuration languge)


WHAT IS TERRAFORM:
its a tool used to make infrastructure automation.
its a free and not open source.
its platform independent.
it comes on the year 2014.
who: Mitchel Hashimoto 
owned: Hashicorp -- > recently IBM is maintaining.
terraform is written on the go language.
We can call terraform as IAC TOOL.
it is Cloud Agonistic (it can used to work with any cloud and even on prem)
it can manage things from onprem also.


HOW IT WORKS:
terraform uses code to automate the infra.
we use HCL : HashiCorp Configuration Language.

IAC: Infrastructure as a code.

Code --- > execute --- > Infra 

ADVANTAGES:
1. Reusable 
2. Time saving
3. Automation
4. Avoiding mistakes
5. Dry run (Dont Repeat Yourself)

CLOUD ALTERNATIVES:
CFT = AWS
ARM = AZURE
GDE = GOOGLE

TERRAFROM = ALL CLOUDS

SOME OTHER ALTERNATIVES:
PULUMI
OpenTofu
ANSIBLE
CHEF
PUPPET



TERRAFORM VS ANSIBLE:
Terraform will create server
and these servers will be configure by ansible.


INSTALLING TERRAFORM:

STEP-1: INSTALLING TERRAFORM

sudo yum install -y yum-utils shadow-utils
sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
sudo yum -y install terraform
terraform --version

NOTE: TERRAFORM IS 3RD PARTY TOOL, SO WE NEED TO GIVE PERMISSION TO TERRAFORM TO WORK WITH AWS
CREATE A ROLE AND ATTACH TO EC2

STEP-2: GIVING IAM ROLE

aws configure (or) give a role
check ll .aws/ for the configuration 

MAIN ITEMS IN FILE:
blocks
lables (name, type of resource)
arguments


Configuration files:
it will have resource configuration.
here we write inputs for our resource 
based on that input terraform will create the real world resources.
extension is .tf 

mkdir terraform
cd terraform

vim main.tf 

provider "aws" {
region = "us-east-1"
}

resource "aws_instance" "one" {
ami = "ami-03eb6185d756497f8"
instance_type = "t2.micro"
}

I : INIT
P : PLAN
A : APPLY
D : DESTROY

TERRAFORM COMMANDS:
terraform init	: initialize the provider plugins on backend
it will store information of plugins in .terraform folder
without plugins we cant create resources.
each provider will have its own plugins.
we can get every provider from terraform registry.
once plugins are downloaded we should not need to run init every time.

PLUGINS: ARE RESPONSIBLE TO CREATE RESOURCES IN CLOUD.

terraform plan	: to create an execution plan
it will take inputs given by users and plan the resource creation
if we haven't given inputs for few fields it will take default values.

terraform apply : to create resources
as per the given inputs on configuration file it will create the resources in real word.

terrafrom destroy : to delete resources

provider "aws" {
region = "us-east-1"
}

resource "aws_instance" "one" {
count = 5
ami = "ami-03eb6185d756497f8"
instance_type = "t2.micro"
}


terraform apply --auto-approve
terraform destroy --auto-approve


STATE FILE: used to store the resource information which is created by terraform
to track the resource activities
in real time entire resource info is on state file.
we need to keep it safe & Secure
if we lost this file we cant track the infra.
Command:
terraform state list

terraform target: used to destroy the specific resource 
terraform state list
single target: terraform destroy -auto-approve -target="aws_instance.one[3]"
multi targets: terraform destroy -auto-approve -target="aws_instance.one[1]" -target="aws_instance.one[2]"


TERRAFORM FMT: 
used to give allignment and indentation for terraform files.
rewrite configuration files to a canonical format and style.
terraform fmt